# ☁️ PAID:Photoacoustic imaging dataset

📚 This repository is a continuously updated, comprehensive collection of all publicly available photoacoustic imaging datasets.

---

## 👥💻 Contributors
- 🧑‍🔬 **SMU Intelligent Optical Tomography Lab**  
  Southern Medical University  
  📧 https://smu-iotlab.github.io/

- 🧑‍🔬 **Chaobin Hu**  
  Southern Medical University  
  📧 cbinhu95@gmail.com

- 🧑‍🔬 **Yutian Zhong**  
  Shanghai Jiao Tong University  
  📧 hanxv8826@gmail.com

- 👨‍🏫 **Li Qi**  
  Southern Medical University
  📧 qili@smu.edu.cn

---

## 📊 GitHub Stats
![Stars](https://img.shields.io/github/stars/CbinHu/PAID-Photoacoustic-imaging-dataset?style=social)
![Forks](https://img.shields.io/github/forks/CbinHu/PAID-Photoacoustic-imaging-dataset?style=social)
![License](https://img.shields.io/github/license/CbinHu/PAID-Photoacoustic-imaging-dataset)
![Last Commit](https://img.shields.io/github/last-commit/CbinHu/PAID-Photoacoustic-imaging-dataset)

---

## 🔍 Project Overview
With the continuous advancement of research on Medical Vision-Language Models (Med-VLMs) and their reasoning capabilities, a number of high-quality, publicly available datasets focusing on medical reasoning have been released between March and May 2025. These datasets provide a solid foundation for the development of multimodal medical AI systems.

**Med-VLM-Bench** is a curated, continuously updated repository of the latest and most important datasets for training and evaluating medical LLMs and VLMs. This project focuses on:

- ✅ Reasoning-centric multimodal benchmarks  
- 📅 Latest datasets published in Mar–May 2025  
- 🧠 Foundational datasets from 2023–2024  
- 🔗 Direct access to dataset links or HuggingFace/GitHub repositories  

💡 Our knowledge is limited to public sources. We welcome community contributions — feel free to open an issue to share new datasets, and we will update promptly. 

📌Note: The annotation time of the dataset is based on the publication time of the corresponding article.

---

## 📢 News

### 🌟 Latest Updates
- **2025-06-29**: 🎉 Added new datasets/benchmarks **AbdomenAtlas 3.0 (ICCV2025)**, **Derm1M(ICCV2025)**, **MedTVT-R1**, **GEMeX(ICCV2025)** and **HIE-Reasoning(ICML2025)**. Check it out for detailed information and download links!
- **2025-06-18**: 🎉 Added new datasets/benchmarks **Lingshu**, **ReasonMed**. Check it out for detailed information and download links!
- **2025-06-11**: 🎉 Added some recent datasets and benchmarks!
- **2025-06-11**: 🎉 Create our GitHub project!

---

## 📊 Dataset Summary Table

| Dataset Name | Paper Title | Year / Venue | Data Modality | Task Type | Size | Download Link |
|--------------|-------------|--------------|---------------|-----------|------|---------------|
| **MedTVT-QA** | [MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis](https://arxiv.org/pdf/2506.18512) | 2025.06.23 | Text + Time Series (ECG) + Image (CXR) + Tabular (Lab Test) | Multimodal Medical Reasoning, Multi-disease Diagnosis, Report Generation | 8,706 multimodal data combinations used to generate QA pairs | [GitHub](https://github.com/keke-nice/MedTVT-R1) |

---
---

## 📊 GitHub Stats
![Stars](https://img.shields.io/github/stars/CbinHu/PAID-Photoacoustic-imaging-dataset?style=social)
![Forks](https://img.shields.io/github/forks/CbinHu/PAID-Photoacoustic-imaging-dataset?style=social)
![License](https://img.shields.io/github/license/CbinHu/PAID-Photoacoustic-imaging-dataset)
![Last Commit](https://img.shields.io/github/last-commit/CbinHu/PAID-Photoacoustic-imaging-dataset)

---

> Last generated: {datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M')} UTC